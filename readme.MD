# Pengantar Deep Learning Dengan PyTorch
> **Tentang Repositori Ini:**
> Repositori ini memuat kumpulan bahan belajar tentang implementasi Deep Learning menggunakan PyTorch




# Daftar Isi

<table class="tg">
  <tr>
    <th class="tg-yw4l"><b>No</b></th>
    <th class="tg-yw4l"><b>Topik</b></th>
    <th class="tg-yw4l"><b>Deskripsi</b></th>
    <th class="tg-yw4l"><b>Notebook</b></th>
  </tr>
  
  <tr>
    <td class="tg-yw4l">1</td>
    <td class="tg-yw4l">Pengantar Tensor</td>
    <td class="tg-yw4l">Memberikan gambaran singkat tentang tipe data tensor dan operasi-operasi aritmatika sederhana menggunakan PyTorch</td>
    <td class="tg-yw4l"><a href="IPYNB Code/01_tensorbasic.ipynb">Tensorbasic</a> </td>
  </tr>

<tr>
    <td class="tg-yw4l">2</td>
    <td class="tg-yw4l">Autograd</td>
    <td class="tg-yw4l">Membahas tentang proses menghitung gradien secara otomatis dengan fungsi autograd</td>
    <td class="tg-yw4l"><a href="IPYNB Code/02_Autograd.ipynb">Autograd</a> </td>
  </tr>

<tr>
    <td class="tg-yw4l">3</td>
    <td class="tg-yw4l">Forward Pass, Backpropagation, Computational Graph</td>
    <td class="tg-yw4l">Membahas tentang proses forward pass dan back-propagation serta keterkaitan antara keduanya. Pada bagian ini juga dibahas bagaimana proses computational graph.</td>
    <td class="tg-yw4l"><a href="IPYNB Code/03_Backprop.ipynb">Backprop</a>
<a href="IPYNB Code/03b_ComputationalGraph.ipynb">CompGraph</a> </td>
  </tr>

<tr>
    <td class="tg-yw4l">4</td>
    <td class="tg-yw4l">Gradient Descent</td>
    <td class="tg-yw4l">Membahas tentang perhitungan gradient descent baik menggunakan numpy maupun dengan torch</td>
    <td class="tg-yw4l"><a href="IPYNB Code/04_graddescent.ipynb">GradDesc1</a>
<a href="IPYNB Code/05_graddescent2.ipynb.ipynb">GradDesc2</a></td>
  </tr>

<tr>
    <td class="tg-yw4l">5</td>
    <td class="tg-yw4l">Training Pipeline</td>
    <td class="tg-yw4l">Proses melakukan training loop dengan pytroch untuk kasus sederhana</td>
    <td class="tg-yw4l"><a href="IPYNB Code/06_training_pipeline.ipynb">Training Pipeline</a></td>
  </tr>

<tr>
    <td class="tg-yw4l">6</td>
    <td class="tg-yw4l">Linear Regression</td>
    <td class="tg-yw4l">Melakukan regresi sederhana dengan deep learning, mengatur hyperparameter, dan melihat hasil prediksi</td>
    <td class="tg-yw4l"><a href="IPYNB Code/07_linearreg.ipynb">Lin-reg1</a>
<a href="IPYNB Code/08_linearreg2.ipynb">Lin-reg2</a></td>
  </tr>

<tr>
    <td class="tg-yw4l">7</td>
    <td class="tg-yw4l">Logistic Regression</td>
    <td class="tg-yw4l">Melakukan logistic regression sederhana dan melakukan transformasi data</td>
    <td class="tg-yw4l"><a href="IPYNB Code/09_logisticreg.ipynb">Logistic Reg</a>
  </tr>

<tr>
    <td class="tg-yw4l">8</td>
    <td class="tg-yw4l">Dataset & Dataloader</td>
    <td class="tg-yw4l">Mempelajari penggunaan dataloader dan proses mempersiapkan dataset pada pytorch</td>
    <td class="tg-yw4l"><a href="IPYNB Code/10_DatasetDataloader.ipynb">DataLoader</a>
  </tr>

<tr>
    <td class="tg-yw4l">9</td>
    <td class="tg-yw4l">Dataset Transform</td>
    <td class="tg-yw4l">Mentransformasikan dataset dengan bantuan dengan fungsi transforms dari pytorch</td>
    <td class="tg-yw4l"><a href="IPYNB Code/11_DatasetTransform.ipynb">Data Transform</a>
  </tr>

<tr>
    <td class="tg-yw4l">10</td>
    <td class="tg-yw4l">Softmax Cross-Entropy</td>
    <td class="tg-yw4l">Mendemonstrasikan fungsi softmax baik dengan pytorch maupun tanpa pytorch. Menghitung loss dengan cross-entropy</td>
    <td class="tg-yw4l"><a href="IPYNB Code/12_SoftmaxAndCrossEnt.ipynb">SoftMax CrossEnt</a>
  </tr>

<tr>
    <td class="tg-yw4l">11</td>
    <td class="tg-yw4l">Activation Function</td>
    <td class="tg-yw4l">Mencoba beberapa fungsi aktivasi yang disediakan pada PyTorch serta teknik implementasinya</td>
    <td class="tg-yw4l"><a href="IPYNB Code/13_activationfunc.ipynb">Act Function</a>
  </tr>

<tr>
    <td class="tg-yw4l">12</td>
    <td class="tg-yw4l">Feed Forward Neural Network</td>
    <td class="tg-yw4l">Mencoba melakukan training dan testing menggunakan dataset tulisan tangan MNIST)</td>
    <td class="tg-yw4l"><a href="IPYNB Code/14_feedforward.ipynb">FFNN MNIST</a>
  </tr>

<tr>
    <td class="tg-yw4l">13</td>
    <td class="tg-yw4l">CNN dengan CIFAR</td>
    <td class="tg-yw4l">Mencoba melakukan training dan testing menggunakan metode konvolusi pada dataset CIFAR</td>
    <td class="tg-yw4l"><a href="IPYNB Code/15_CNNCIFAR.ipynb">CNN-CIFAR</a>
  </tr>

</table>

# Instalasi dan Prasyarat
(akan ditambahkan kemudian)

# Saran dan Pengembangan
Materi yang ada pada repositori ini bersifat gratis dan akan selalu tersedia secara gratis. Kami berterima kasih apabila ada pihak-pihak yang ingin membantu dan mengoreksi konten dari repositori ini. Silahkan tambahkan [issue baru](https://github.com/mctosima/pengantarDLpytorch/issues) agar kami dapat melacak kesalahan maupun saran perbaikan yang ada

Kami menyadari bahwa konten ini tidak sepenuhnya bersumber dari diri kami sendiri. Atribusi dan pencantuman sumber sebisa mungkin dilakukan untuk memberikan kredit kepada pembuat. Apabila anda sebagai pembuat materi / asset yang digunakan pada repositori ini merasa keberatan, kami dengan senang hati akan memperbaiki dan menghapus materi / asset anda dari repositori ini.

# Lisensi dan Atribusi
Seluruh kode dan materi yang ada di dalam repositori ini menggunakan lisensi MIT. Anda dapat dengan bebas melakukan:
- Menggunakannya untuk keperluan komersial
- Memodifikasi dan menggunakannya untuk keperluan pribadi
- dan Mendistribusikannya untuk kepentingan luas

Apabila anda menggunakan kode dan materi yang ada di dalam repositori ini untuk keperluan komersial, riset, dan pendidikan, mohon cantumkan atribusi terhadap pemilik repositori:
```angular2html
@misc{mctiww2022,
  title={Pengantar Deep Learning Dengan Pytorch},
  author={Manullang, Martin Clinton Tosima and Wisesa, I Wayan Wiprayoga},
  journal={https://github.com/mctosima/pengantarDLpytorch},
  year={2022}
```

# Referensi
- Krizhevsky, A. (n.d.). Learning Multiple Layers of Features from Tiny Images. https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf
- MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges. (n.d.). Retrieved April 13, 2022, from http://yann.lecun.com/exdb/mnist/
- PyTorch documentation â€” PyTorch 1.11.0 documentation. (n.d.). Retrieved April 13, 2022, from https://pytorch.org/docs/stable/index.html
- Activation functions in Neural Networks. (2018, January 29). GeeksforGeeks. https://www.geeksforgeeks.org/activation-functions-neural-networks/
- Engineer, P. (2021, February 24). Deep Learning With PyTorch - Full Course. Youtube. https://www.youtube.com/watch?v=c36lUUr864M
- Engineer), P. L. (python. (n.d.). pytorchTutorial: PyTorch Tutorials from my YouTube channel. Github. Retrieved April 13, 2022, from https://github.com/python-engineer/pytorchTutorial 
- PyTorch Tutorial. (n.d.). Retrieved April 13, 2022, from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html