{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Learning Rate Scheduler**\n",
    "\n",
    "_Learning rate scheduler adalah sebuah algoritma yang menentukan besarnya learning rate (learning rate) yang akan digunakan. `torch.optim.lr_scheduler` menyediakan beberapa metode untuk menyesuaikan learning rate berdasarkan epoch_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Mengimpor Library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Mendefinisikan Model dan Learning Rate\n",
    "- Untuk contoh pembelajaran, model yang kita gunakan hanya berupa sebuah fully connected layer dengan jumlah input dan output yang kecil\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate      = 0.01\n",
    "model       = nn.Linear(4,1)\n",
    "optim       = torch.optim.Adam(model.parameters(), lr=l_rate)\n",
    "epochs      = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda LR\n",
    "\n",
    "Pada contoh kali ini kita akan menggunakan salah satu jenis scheduler yaitu `LambdaLR`. LambdaLR adalah sebuah scheduler yang menggunakan fungsi lambda untuk menentukan learning rate. Parameter yang diberikan kepada LambdaLR adalah:\n",
    "- `optimizer`: optimizer yang akan digunakan untuk mengatur learning rate\n",
    "- `lambda`: fungsi lambda yang akan digunakan untuk menentukan learning rate\n",
    "- `last_epoch`: epoch terakhir yang telah dilakukan, nilai ini akan digunakan untuk menentukan learning rate yang akan digunakan pada epoch terakhir. Defaultnya adalah -1.\n",
    "- `verbose`: boolean yang menentukan apakah akan menampilkan pesan atau tidak. Defaultnya adalah False.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**Review Fungsi Lambda di Python**\n",
    "\n",
    "</div>\n",
    "\n",
    "> Sebelum melanjutkan pembahasan tentang scheduler, mari kita review sejenak tentang fungsi lambda di python.\n",
    "\n",
    "Misalkan kita memiliki sebuah fungsi sederhana, yang menerima input `x`, dan mengembalikan nilai `x+3`\n",
    "\n",
    "```python\n",
    "def func(x):\n",
    "    return x+3\n",
    "```\n",
    "\n",
    "maka cara lain untuk menulis fungsi ini dapat menggunakan `lambda` yaitu sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "func = lambda x: x+3\n",
    "\n",
    "# mencoba fungsi lambda dengan memberikan masukan 3\n",
    "print(func(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita lanjutkan pembahasan Lambda LR. Selanjutnya, kita akan membuat sebuah scheduler yang menggunakan fungsi lambda sebagai berikut:\n",
    "- Fungsi kita beri nama `f_lambda`\n",
    "- Fungsi akan menerima masukan berupa epoch\n",
    "- Fungsi akan mengembalikan nilai berupa epoch dibagi dengan 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lambda = lambda epoch: epoch/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memuat scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.LambdaLR(optim,f_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melihat perubahan learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kondisi Awal:{'state': {}, 'param_groups': [{'lr': 0.0, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'initial_lr': 0.01, 'params': [0, 1]}]}\n",
      "LR pada Epoch ke-1 adalah 0.001\n",
      "LR pada Epoch ke-2 adalah 0.002\n",
      "LR pada Epoch ke-3 adalah 0.003\n",
      "LR pada Epoch ke-4 adalah 0.004\n",
      "LR pada Epoch ke-5 adalah 0.005\n"
     ]
    }
   ],
   "source": [
    "print(f'Kondisi Awal:{optim.state_dict()}')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # proses loss.backward() ditempatkan di sini\n",
    "    optim.step()\n",
    "    # proses validasi ditempatkan di sini\n",
    "    scheduler.step()\n",
    "    print(f'LR pada Epoch ke-{epoch+1} adalah {optim.param_groups[0][\"lr\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penjelasan\n",
    "- Dapat kita amati bahwa LR pada epoch ke-1 adalah 0.001\n",
    "- Nilai ini didapat dari fungsi `lambda` yang kita buat sebelumnya dimana `f_lambda` menerima `epoch = 1` dan mengembalikan nilai `f_lambda = 0.1`\n",
    "- Selanjutnya scheduler mengubah nilai learning rate pada epoch ke 1 dengan cara mengalikan nilai awal learning rate (0.01) dengan nilai `f_lambda` saat itu yaitu `0.1` sehingga pada epoch ke-1 nilai LR menjadi $0.01 * 0.1 = 0.001$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catatan Lanjutan\n",
    "\n",
    "Tentunya masih banyak jenis scheduler yang tidak dibahas pada modul ini. Anda dapat mencobanya sendiri.\n",
    "\n",
    "**Mengapa menggunakan scheduler?**\n",
    "Ada banyak alasan mengapa perubahan learning rate di tiap epoch perlu dilakukan, misalnya masalah [vanishing / exploding gradient](https://towardsdatascience.com/the-exploding-and-vanishing-gradients-problem-in-time-series-6b87d558d22). Nilai LR yang besar akan menyebabkan parameter pada model menjadi sangat cepat untuk berubah, sebaliknya jika terlalu kecil maka akan membutuhkan semakin banyak epoch untuk mencapai kondisi model yang ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referensi\n",
    "- [`torch.optim`](https://pytorch.org/docs/stable/optim.html)\n",
    "- [Patrick Loerber, Python Engineer @ Youtube](https://www.youtube.com/watch?v=81NJgoR5RfY&list=WL&index=2&t=9s)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48b01bbe2a5925c925c77e8564d4aca619d3db5d4d3ae75ad89e487aa7bce479"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch-nightly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
