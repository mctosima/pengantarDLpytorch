{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Softmax\n",
    "Berikut adalah persamaan dari softmax function\n",
    "$S(y_i) = \\frac{e^{y_i}}{\\sum_{j=1}^{n}e^{y_j}}$\n",
    "\n",
    "**Berikut beberapa hal penting terkait softmax:**\n",
    "- Softmax function atau ***normalized exponential function*** adalah generalisasi dari fungsi logistik terhadap beberapa dimensi\n",
    "- Kerap digunakan sebagai fungsi aktivasi untuk menghasilkan probabilitas (antara 0 dan 1)\n",
    "- Input dari softmax adalah sebuah vektor yang berisi nilai dari suatu variabel, menormalisasikannya menjadi distribusi probabilitas\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"../assets/softmaxlayer.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "**Perhatikan ilustrasi diatas ini:**\n",
    "- Setiap nilai akan di ***squashed*** menjadi nilai probabilitas\n",
    "- Misalnya nilai terendah (0.1) menjadi 0.1 dan nilai tertinggu (2) menjadi 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fungsi Softmax Tanpa Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [2.  1.  0.1]\n",
      "Output: [0.65900114 0.24243297 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print(f'Input: {x}')\n",
    "print(f'Output: {outputs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fungsi Softmax Dengan Torch\n",
    "```torch.softmax(input, dimensi)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([2.0000, 1.0000, 0.1000])\n",
      "Output: tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(f'Input: {x}')\n",
    "print(f'Output: {outputs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Ilustrasi Softmax\n",
    "Sehingga dapat diamati, jika softmax digunakan dalam NN layers, maka implementasinya akan seperti gambar di bawah ini.\n",
    "\n",
    "<div>\n",
    "<img src=\"../assets/softmax2.jpeg\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "Sumber: [Towards Data Science](https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e#:~:text=than%20in%202.-,Cross%2DEntropy%20Loss%20Function,from%20the%20actual%20expected%20value.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cross-Entropy Loss\n",
    "Kita sebelumnya memahami bahwa softmax mengubah nilai dari suatu variabel menjadi distribusi probabilitas. Tujuan dari cross-entropy loss adalah untuk menghitung error dari softmax. Cross entropy menggunakan hasil dari softmax sebagai input dan mengukur jarak dari nilai kebenaran (truth values).\n",
    "\n",
    "**Cross-Entropy Loss Equation**\n",
    "$D(\\widehat{y}, y) = -\\sum_{i=1}^{n}y_i\\log(\\hat{y}_i)$\n",
    "\n",
    "**Contoh 1:**\n",
    "$Y = [1,0,0]$\n",
    "$\\hat{Y} = [0.7,0.2,0.1]$\n",
    "$D(\\hat{Y}, Y) = 0.35$\n",
    "**Contoh 2:**\n",
    "$Y = [1,0,0]$\n",
    "$\\hat{Y} = [0.1,0.3,0.6]$\n",
    "$D(\\hat{Y}, Y) = 2.30$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implementasi tanpa Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 0.357\n",
      "Loss 2: 2.303\n",
      "Loss 3: 0.000\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_loss(sebenarnya, prediksi):\n",
    "    return -np.sum(sebenarnya * np.log(prediksi))\n",
    "\n",
    "\n",
    "Y = np.array([1.0, 0.0, 0.0])\n",
    "Y_prediksi = np.array([0.7, 0.2, 0.1])\n",
    "Y_prediksi_2 = np.array([0.1, 0.3, 0.6])\n",
    "Y_prediksi_perfect = np.array([0.999998, 0.000001, 0.000001]) # contoh distribusi yang sangat mirip dengan `Y`\n",
    "\n",
    "loss_1 = cross_entropy_loss(Y, Y_prediksi)\n",
    "loss_2 = cross_entropy_loss(Y, Y_prediksi_2)\n",
    "loss_3 = cross_entropy_loss(Y, Y_prediksi_perfect)\n",
    "\n",
    "print(f'Loss 1: {loss_1:.3f}')\n",
    "print(f'Loss 2: {loss_2:.3f}')\n",
    "print(f'Loss 3: {loss_3:.3f}')  # karena distribusi sangat mirip, seharusnya nilai loss sangat kecil mendekati 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implementasi dengan Torch\n",
    "\n",
    "```nn.CrossEntropyLoss()```\n",
    "- CrossEntropyLoss adalah loss function yang menggunakan softmax sebagai input dan menghitung error dari softmax\n",
    "- Pada fungsi ini, softmax akan dihitung secara otomatis\n",
    "- Softmax tidak perlu ditempatkan lagi di layer sebelumnya\n",
    "- ```Y``` harus berupa class labels, dapat juga dalam bentuk [one-hot-encoding](https://en.wikipedia.org/wiki/One-hot) atau juga probabilitas kelas\n",
    "- ```Y_prediksi``` harus berupa nilai yang belum di-softmax. [Lihat dokumentasi](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 0.417\n",
      "Loss 2: 1.841\n",
      "Loss 3: 0.000\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0])\n",
    "Y_prediksi = torch.tensor([[2.0, 1.0, 0.1]])  # Raw Value tanpa Softmax\n",
    "Y_prediksi_2 = torch.tensor([[0.5, 2.0, 0.3]])  # Raw Value tanpa Softmax\n",
    "Y_prediksi_perfect = torch.tensor([[10.0, 0.3, 0.1]]) # contoh distribusi yang sangat mirip dengan `Y` (raw value)\n",
    "\n",
    "loss_1 = loss(Y_prediksi, Y)\n",
    "loss_2 = loss(Y_prediksi_2, Y)\n",
    "loss_3 = loss(Y_prediksi_perfect, Y)\n",
    "\n",
    "print(f'Loss 1: {loss_1.item():.3f}')\n",
    "print(f'Loss 2: {loss_2.item():.3f}')\n",
    "print(f'Loss 3: {loss_3.item():.3f}')  # karena distribusi sangat mirip, seharusnya nilai loss sangat kecil mendekati 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 0.417\n",
      "Loss 2: 1.841\n",
      "Loss 3: 0.000\n"
     ]
    }
   ],
   "source": [
    "# contoh dengan target merupakan one-hot-encoding\n",
    "# --- seharusnya hasil sama dengan kode diatas ---\n",
    "Y = torch.tensor([[1.0, 0.0, 0.0]], dtype=torch.float)\n",
    "Y_prediksi = torch.tensor([[2.0, 1.0, 0.1]])  # Raw Value tanpa Softmax\n",
    "Y_prediksi_2 = torch.tensor([[0.5, 2.0, 0.3]])  # Raw Value tanpa Softmax\n",
    "Y_prediksi_perfect = torch.tensor([[10.0, 0.3, 0.1]]) # contoh distribusi yang sangat mirip dengan `Y` (raw value)\n",
    "\n",
    "loss_1 = loss(Y_prediksi, Y)\n",
    "loss_2 = loss(Y_prediksi_2, Y)\n",
    "loss_3 = loss(Y_prediksi_perfect, Y)\n",
    "\n",
    "print(f'Loss 1: {loss_1.item():.3f}')\n",
    "print(f'Loss 2: {loss_2.item():.3f}')\n",
    "print(f'Loss 3: {loss_3.item():.3f}')  # karena distribusi sangat mirip, seharusnya nilai loss sangat kecil mendekati 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Mengambil prediksi terbaik\n",
    "Menggunakan ```torch.max``` untuk mendapatkan prediksi terbaik. Fungsi ini mengembalikan nilai maksimum dan index maksimum.\n",
    "\n",
    "Format input : ```torch.max(input, dim)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi-1 terbaik adalah elemen ke: 0\n",
      "Prediksi-2 terbaik adalah elemen ke: 1\n",
      "Prediksi-3 terbaik adalah elemen ke: 0\n"
     ]
    }
   ],
   "source": [
    "_, prediksi1 = torch.max(Y_prediksi, 1)\n",
    "_, prediksi2 = torch.max(Y_prediksi_2, 1)\n",
    "_, prediksi3 = torch.max(Y_prediksi_perfect, 1)\n",
    "print(f'Prediksi-1 terbaik adalah elemen ke: {prediksi1.item()}')\n",
    "print(f'Prediksi-2 terbaik adalah elemen ke: {prediksi2.item()}')\n",
    "print(f'Prediksi-3 terbaik adalah elemen ke: {prediksi3.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}