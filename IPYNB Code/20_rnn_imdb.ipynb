{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "vocabulary_size = 20000\n",
    "lr = 0.005\n",
    "batch_size = 128\n",
    "num_epochs = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset\n",
    "[Dataset Link](https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text_column  label_column\n0  In 1974, the teenager Martha Moxley (Maggie Gr...             1\n1  OK... so... I really like Kris Kristofferson a...             0\n2  ***SPOILER*** Do not read this, if you think a...             0\n3  hi for all the people who have seen this wonde...             1\n4  I recently bought the DVD, forgetting just how...             0\n5  Leave it to Braik to put on a good show. Final...             1\n6  Nathan Detroit (Frank Sinatra) is the manager ...             1\n7  To understand \"Crash Course\" in the right cont...             1\n8  I've been impressed with Chavez's stance again...             1\n9  This movie is directed by Renny Harlin the fin...             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_column</th>\n      <th>label_column</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OK... so... I really like Kris Kristofferson a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>***SPOILER*** Do not read this, if you think a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hi for all the people who have seen this wonde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I recently bought the DVD, forgetting just how...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Leave it to Braik to put on a good show. Final...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Nathan Detroit (Frank Sinatra) is the manager ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>To understand \"Crash Course\" in the right cont...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I've been impressed with Chavez's stance again...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>This movie is directed by Renny Harlin the fin...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataaset csv disimpan dalam folder `data` dengan lokasi relatif satu level diatas notebook ini\n",
    "dataset_path = '../data/movie_data.csv' \n",
    "df = pd.read_csv(dataset_path)\n",
    "df.columns = ['text_column', 'label_column']\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/movie_data_cleaned.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mempersiapkan Data\n",
    "\n",
    "**Prasyarat:**\n",
    "- Paket `spacy` harus sudah terinstall di python anda\n",
    "- Anda juga perlu mengunduh vocabulary bahasa inggris dari spacy dengan cara mengetikkan perintah di bawah ini pada terminal anda\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "- Versi `torchtext` yang digunakan dalam tutorial ini adalah `0.6.0`. Jika anda ingin menggunakan `torchtext` versi terbaru, silahkan merujuk pada [standar API baru torchtext](https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb#scrollTo=jXUgsnxw70-M)\n",
    "- Tokenize akan mengubah kalimat pada teks menjadi token. Misalnya : `'Hello world'` menjadi `['Hello', 'world']`\n",
    "- Detail tentang `torchtext.data` dapat dilihat pada [tautan berikut](https://torchtext.readthedocs.io/en/latest/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_column': ['In', '1974', ',', 'the', 'teenager', 'Martha', 'Moxley', '(', 'Maggie', 'Grace', ')', 'moves', 'to', 'the', 'high', '-', 'class', 'area', 'of', 'Belle', 'Haven', ',', 'Greenwich', ',', 'Connecticut', '.', 'On', 'the', 'Mischief', 'Night', ',', 'eve', 'of', 'Halloween', ',', 'she', 'was', 'murdered', 'in', 'the', 'backyard', 'of', 'her', 'house', 'and', 'her', 'murder', 'remained', 'unsolved', '.', 'Twenty', '-', 'two', 'years', 'later', ',', 'the', 'writer', 'Mark', 'Fuhrman', '(', 'Christopher', 'Meloni', ')', ',', 'who', 'is', 'a', 'former', 'LA', 'detective', 'that', 'has', 'fallen', 'in', 'disgrace', 'for', 'perjury', 'in', 'O.J.', 'Simpson', 'trial', 'and', 'moved', 'to', 'Idaho', ',', 'decides', 'to', 'investigate', 'the', 'case', 'with', 'his', 'partner', 'Stephen', 'Weeks', '(', 'Andrew', 'Mitchell', ')', 'with', 'the', 'purpose', 'of', 'writing', 'a', 'book', '.', 'The', 'locals', 'squirm', 'and', 'do', 'not', 'welcome', 'them', ',', 'but', 'with', 'the', 'support', 'of', 'the', 'retired', 'detective', 'Steve', 'Carroll', '(', 'Robert', 'Forster', ')', 'that', 'was', 'in', 'charge', 'of', 'the', 'investigation', 'in', 'the', '70', \"'s\", ',', 'they', 'discover', 'the', 'criminal', 'and', 'a', 'net', 'of', 'power', 'and', 'money', 'to', 'cover', 'the', 'murder.<br', '/><br', '/>\"Murder', 'in', 'Greenwich', '\"', 'is', 'a', 'good', 'TV', 'movie', ',', 'with', 'the', 'true', 'story', 'of', 'a', 'murder', 'of', 'a', 'fifteen', 'years', 'old', 'girl', 'that', 'was', 'committed', 'by', 'a', 'wealthy', 'teenager', 'whose', 'mother', 'was', 'a', 'Kennedy', '.', 'The', 'powerful', 'and', 'rich', 'family', 'used', 'their', 'influence', 'to', 'cover', 'the', 'murder', 'for', 'more', 'than', 'twenty', 'years', '.', 'However', ',', 'a', 'snoopy', 'detective', 'and', 'convicted', 'perjurer', 'in', 'disgrace', 'was', 'able', 'to', 'disclose', 'how', 'the', 'hideous', 'crime', 'was', 'committed', '.', 'The', 'screenplay', 'shows', 'the', 'investigation', 'of', 'Mark', 'and', 'the', 'last', 'days', 'of', 'Martha', 'in', 'parallel', ',', 'but', 'there', 'is', 'a', 'lack', 'of', 'the', 'emotion', 'in', 'the', 'dramatization', '.', 'My', 'vote', 'is', 'seven.<br', '/><br', '/>Title', '(', 'Brazil', '):', 'Not', 'Available'], 'label_column': '1'}\n"
     ]
    }
   ],
   "source": [
    "text = torchtext.data.Field(\n",
    "    tokenize = 'spacy',\n",
    "    tokenizer_language='en_core_web_sm',\n",
    ")\n",
    "\n",
    "label = torchtext.data.LabelField(dtype=torch.long)\n",
    "\n",
    "fields = [('text_column', text), ('label_column', label)]\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path='../data/movie_data_cleaned.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=fields,\n",
    ")\n",
    "\n",
    "print(vars(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 35000\n",
      "Test data size: 10000\n",
      "Validation data size: 5000\n",
      "{'text_column': ['Pros', ':', 'Nothing', '<', 'br', '/><br', '/>Cons', ':', 'Everything', '<', 'br', '/><br', '/>Plot', 'summary', ':', 'A', 'female', 'reporter', 'runs', 'into', 'a', 'hitchhiker', 'that', 'tells', 'her', 'stories', 'about', 'the', 'deaths', 'of', 'people', 'that', 'were', 'killed', 'by', 'zombies.<br', '/><br', '/>Review', ':', 'Never', 'in', 'my', 'life', 'have', 'I', 'come', 'across', 'a', 'movie', 'as', 'bad', 'The', 'Zombie', 'Chronicles', '.', 'Filmed', 'on', 'a', 'budget', 'of', 'what', 'looks', 'to', 'be', 'about', '20', 'bucks', ',', 'TZC', 'is', 'a', 'completely', 'horrible', 'horror', 'movie', 'that', 'relies', 'on', 'lame', ',', 'forgetable', 'actors', 'whom', 'could', \"n't\", 'act', 'to', 'save', 'their', 'lives', 'and', 'gore', 'that', \"'s\", 'more', 'gross', 'than', 'frightening', '.', 'How', 'does', 'a', 'movie', 'like', 'this', 'even', 'get', 'made', '?', 'Simply', 'put', ',', 'avoid', 'TZC', 'like', 'a', 'sexually', '-', 'transmitted', 'disease.<br', '/><br', '/>My', 'last', '2', 'cents', ':', 'Humorously', 'enough', ',', 'this', 'movie', 'was', 'made', 'by', 'a', 'movie', 'company', 'called', 'Brain', 'Damage', 'Films', '.', 'They', \"'re\", 'brains', 'must', 'have', 'really', 'been', 'damaged', 'to', 'come', 'up', 'with', 'a', 'craptacular', 'movie', 'like', 'this.<br', '/><br', '/>My', 'rating', ':', '1', 'out', 'of', '10(If', 'it', 'were', 'up', 'to', 'me', ',', 'this', 'movie', 'would', 'get', 'the', 'rating', 'of', 'negative', 'bajillion', ')'], 'label_column': '0'}\n"
     ]
    }
   ],
   "source": [
    "# train_data, test_data, val_data = random_split(\n",
    "#     dataset,\n",
    "#     [int(len(dataset) * 0.7), int(len(dataset) * 0.2), int(len(dataset) * 0.1)],\n",
    "#     torch.Generator().manual_seed(random_seed),\n",
    "# )\n",
    "\n",
    "train_data, val_data, test_data = dataset.split(\n",
    "    split_ratio=[0.7, 0.2, 0.1],\n",
    "    random_state = random.seed(random_seed),\n",
    ")\n",
    "\n",
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Test data size: {len(test_data)}')\n",
    "print(f'Validation data size: {len(val_data)}')\n",
    "\n",
    "# Mengecek contoh train_data\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membangun Vocabulary / Kamus Kata\n",
    "- Vocabulary dibatasi sebesar 20000 (hanya menampilkan 20000 kata yang paling sering dipakai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "Label size: 2\n"
     ]
    }
   ],
   "source": [
    "text.build_vocab(train_data, max_size=vocabulary_size)\n",
    "label.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(text.vocab)}')\n",
    "print(f'Label size: {len(label.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 402761), (',', 381621), ('.', 328787), ('and', 217039), ('a', 216689), ('of', 200379), ('to', 185267), ('is', 150020), ('in', 122410), ('I', 108843), ('it', 106563), ('that', 96538), ('\"', 89116), (\"'s\", 85279), ('this', 84271), ('-', 73508), ('/><br', 70760), ('was', 69368), ('as', 59751), ('movie', 59142)]\n",
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
      "5\n",
      "defaultdict(None, {'1': 0, '0': 1})\n"
     ]
    }
   ],
   "source": [
    "# kata yang paling banyak muncul\n",
    "print(text.vocab.freqs.most_common(20))\n",
    "\n",
    "# 10 entri pertama (integer to string)\n",
    "print(text.vocab.itos[:10])\n",
    "\n",
    "# stoi : string to integer\n",
    "print(text.vocab.stoi['and'])\n",
    "\n",
    "# Label '1' atau positif ada di index 0, sementara label '0' atau negatif ada di indeks 1\n",
    "print(label.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 946x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 1068x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 60x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 52x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=False,\n",
    "    sort_key=lambda x: len(x.text_column),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "check_iter = iter(train_loader)\n",
    "print(next(check_iter))\n",
    "print(next(check_iter))\n",
    "\n",
    "check_iter = iter(val_loader)\n",
    "print(next(check_iter))\n",
    "\n",
    "check_iter = iter(test_loader)\n",
    "print(next(check_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        # self.rnn = nn.RNN(embedding_dim, hidden_dim, nonlinearity='relu')\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        output = self.embedding(text)\n",
    "        output, (hidden, cell) = self.rnn(output)\n",
    "        hidden.squeeze_()\n",
    "        final_output = self.fc(hidden)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_size=len(text.vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_size=num_classes\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data.text_column.to(device)\n",
    "        labels = batch_data.label_column.to(device)\n",
    "        \n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch: {epoch} | Batch: {batch_idx}/{len(train_loader)} | Loss: {loss:.4f}')\n",
    "            \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        prediksi_benar = 0\n",
    "        jumlah_example = 0\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            \n",
    "            text = batch_data.text_column.to(device)\n",
    "            labels = batch_data.label_column.to(device)\n",
    "            \n",
    "            logits = model(text)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            \n",
    "            jumlah_example += len(preds)\n",
    "            prediksi_benar += (preds == labels).sum().item()\n",
    "            \n",
    "        print(f'Epoch: {epoch} | Accuracy: {prediksi_benar / jumlah_example}')\n",
    "\n",
    "print(f'Train time: {time.time() - train_start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0/79 | Accuracy: 0.9140625\n",
      "Batch: 1/79 | Accuracy: 0.87109375\n",
      "Batch: 2/79 | Accuracy: 0.859375\n",
      "Batch: 3/79 | Accuracy: 0.849609375\n",
      "Batch: 4/79 | Accuracy: 0.8515625\n",
      "Batch: 5/79 | Accuracy: 0.8463541666666666\n",
      "Batch: 6/79 | Accuracy: 0.8359375\n",
      "Batch: 7/79 | Accuracy: 0.8251953125\n",
      "Batch: 8/79 | Accuracy: 0.8255208333333334\n",
      "Batch: 9/79 | Accuracy: 0.8171875\n",
      "Batch: 10/79 | Accuracy: 0.8153409090909091\n",
      "Batch: 11/79 | Accuracy: 0.814453125\n",
      "Batch: 12/79 | Accuracy: 0.8167067307692307\n",
      "Batch: 13/79 | Accuracy: 0.8169642857142857\n",
      "Batch: 14/79 | Accuracy: 0.81875\n",
      "Batch: 15/79 | Accuracy: 0.82080078125\n",
      "Batch: 16/79 | Accuracy: 0.8193933823529411\n",
      "Batch: 17/79 | Accuracy: 0.8185763888888888\n",
      "Batch: 18/79 | Accuracy: 0.8170230263157895\n",
      "Batch: 19/79 | Accuracy: 0.816015625\n",
      "Batch: 20/79 | Accuracy: 0.8177083333333334\n",
      "Batch: 21/79 | Accuracy: 0.8196022727272727\n",
      "Batch: 22/79 | Accuracy: 0.8206521739130435\n",
      "Batch: 23/79 | Accuracy: 0.8206380208333334\n",
      "Batch: 24/79 | Accuracy: 0.8190625\n",
      "Batch: 25/79 | Accuracy: 0.8188100961538461\n",
      "Batch: 26/79 | Accuracy: 0.8194444444444444\n",
      "Batch: 27/79 | Accuracy: 0.8186383928571429\n",
      "Batch: 28/79 | Accuracy: 0.8195043103448276\n",
      "Batch: 29/79 | Accuracy: 0.8197916666666667\n",
      "Batch: 30/79 | Accuracy: 0.8188004032258065\n",
      "Batch: 31/79 | Accuracy: 0.81982421875\n",
      "Batch: 32/79 | Accuracy: 0.8200757575757576\n",
      "Batch: 33/79 | Accuracy: 0.8203125\n",
      "Batch: 34/79 | Accuracy: 0.8194196428571429\n",
      "Batch: 35/79 | Accuracy: 0.8192274305555556\n",
      "Batch: 36/79 | Accuracy: 0.8182010135135135\n",
      "Batch: 37/79 | Accuracy: 0.8168174342105263\n",
      "Batch: 38/79 | Accuracy: 0.8163060897435898\n",
      "Batch: 39/79 | Accuracy: 0.8166015625\n",
      "Batch: 40/79 | Accuracy: 0.8161204268292683\n",
      "Batch: 41/79 | Accuracy: 0.8171502976190477\n",
      "Batch: 42/79 | Accuracy: 0.8175872093023255\n",
      "Batch: 43/79 | Accuracy: 0.8169389204545454\n",
      "Batch: 44/79 | Accuracy: 0.8163194444444445\n",
      "Batch: 45/79 | Accuracy: 0.8155570652173914\n",
      "Batch: 46/79 | Accuracy: 0.8134973404255319\n",
      "Batch: 47/79 | Accuracy: 0.81494140625\n",
      "Batch: 48/79 | Accuracy: 0.8144132653061225\n",
      "Batch: 49/79 | Accuracy: 0.81359375\n",
      "Batch: 50/79 | Accuracy: 0.8138786764705882\n",
      "Batch: 51/79 | Accuracy: 0.8135516826923077\n",
      "Batch: 52/79 | Accuracy: 0.8127948113207547\n",
      "Batch: 53/79 | Accuracy: 0.8127893518518519\n",
      "Batch: 54/79 | Accuracy: 0.8130681818181819\n",
      "Batch: 55/79 | Accuracy: 0.8127790178571429\n",
      "Batch: 56/79 | Accuracy: 0.8126370614035088\n",
      "Batch: 57/79 | Accuracy: 0.8130387931034483\n",
      "Batch: 58/79 | Accuracy: 0.8126324152542372\n",
      "Batch: 59/79 | Accuracy: 0.8123697916666667\n",
      "Batch: 60/79 | Accuracy: 0.813140368852459\n",
      "Batch: 61/79 | Accuracy: 0.8128780241935484\n",
      "Batch: 62/79 | Accuracy: 0.8123759920634921\n",
      "Batch: 63/79 | Accuracy: 0.8125\n",
      "Batch: 64/79 | Accuracy: 0.8131009615384616\n",
      "Batch: 65/79 | Accuracy: 0.8136837121212122\n",
      "Batch: 66/79 | Accuracy: 0.8140158582089553\n",
      "Batch: 67/79 | Accuracy: 0.8143382352941176\n",
      "Batch: 68/79 | Accuracy: 0.8152173913043478\n",
      "Batch: 69/79 | Accuracy: 0.8157366071428571\n",
      "Batch: 70/79 | Accuracy: 0.8158010563380281\n",
      "Batch: 71/79 | Accuracy: 0.8147786458333334\n",
      "Batch: 72/79 | Accuracy: 0.8146404109589042\n",
      "Batch: 73/79 | Accuracy: 0.8145059121621622\n",
      "Batch: 74/79 | Accuracy: 0.8139583333333333\n",
      "Batch: 75/79 | Accuracy: 0.8131167763157895\n",
      "Batch: 76/79 | Accuracy: 0.8131087662337663\n",
      "Batch: 77/79 | Accuracy: 0.813301282051282\n",
      "Batch: 78/79 | Accuracy: 0.8131\n",
      "Test accuracy: 0.8131\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load model dari '../assets/model.pth' (Karena laptop saya tidak kuat nge-train model)\n",
    "jika anda tidak ingin menggunakan pre-trained model, berikan comment pada line di bawah ini (line 6)\n",
    "'''\n",
    "\n",
    "model.load_state_dict(torch.load('../assets/model.pth'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    prediksi_benar = 0\n",
    "    jumlah_example = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(test_loader):\n",
    "\n",
    "        text = batch_data.text_column.to(device)\n",
    "        labels = batch_data.label_column.to(device)\n",
    "\n",
    "        logits = model(text)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "\n",
    "        jumlah_example += len(preds)\n",
    "        prediksi_benar += (preds == labels).sum().item()\n",
    "\n",
    "        print(f'Batch: {batch_idx}/{len(test_loader)} | Accuracy: {prediksi_benar / jumlah_example}')\n",
    "\n",
    "    print(f'Test accuracy: {prediksi_benar / jumlah_example}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81b9ccaf5ef21c8a6faa6d42f6e42fcf9eafd7625a2befdd601079168fccee32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}