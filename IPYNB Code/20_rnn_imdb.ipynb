{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "vocabulary_size = 20000\n",
    "lr = 0.005\n",
    "batch_size = 128\n",
    "num_epochs = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset\n",
    "[Dataset Link](https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                         text_column  label_column\n0  In 1974, the teenager Martha Moxley (Maggie Gr...             1\n1  OK... so... I really like Kris Kristofferson a...             0\n2  ***SPOILER*** Do not read this, if you think a...             0\n3  hi for all the people who have seen this wonde...             1\n4  I recently bought the DVD, forgetting just how...             0\n5  Leave it to Braik to put on a good show. Final...             1\n6  Nathan Detroit (Frank Sinatra) is the manager ...             1\n7  To understand \"Crash Course\" in the right cont...             1\n8  I've been impressed with Chavez's stance again...             1\n9  This movie is directed by Renny Harlin the fin...             1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_column</th>\n      <th>label_column</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OK... so... I really like Kris Kristofferson a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>***SPOILER*** Do not read this, if you think a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hi for all the people who have seen this wonde...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I recently bought the DVD, forgetting just how...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Leave it to Braik to put on a good show. Final...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Nathan Detroit (Frank Sinatra) is the manager ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>To understand \"Crash Course\" in the right cont...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>I've been impressed with Chavez's stance again...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>This movie is directed by Renny Harlin the fin...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataaset csv disimpan dalam folder `data` dengan lokasi relatif satu level diatas notebook ini\n",
    "dataset_path = '../data/movie_data.csv' \n",
    "df = pd.read_csv(dataset_path)\n",
    "df.columns = ['text_column', 'label_column']\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/movie_data_cleaned.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mempersiapkan Data\n",
    "\n",
    "**Prasyarat:**\n",
    "- Paket `spacy` harus sudah terinstall di python anda\n",
    "- Anda juga perlu mengunduh vocabulary bahasa inggris dari spacy dengan cara mengetikkan perintah di bawah ini pada terminal anda\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "- Versi `torchtext` yang digunakan dalam tutorial ini adalah `0.6.0`. Jika anda ingin menggunakan `torchtext` versi terbaru, silahkan merujuk pada [standar API baru torchtext](https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb#scrollTo=jXUgsnxw70-M)\n",
    "- Tokenize akan mengubah kalimat pada teks menjadi token. Misalnya : `'Hello world'` menjadi `['Hello', 'world']`\n",
    "- Detail tentang `torchtext.data` dapat dilihat pada [tautan berikut](https://torchtext.readthedocs.io/en/latest/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_column': ['In', '1974', ',', 'the', 'teenager', 'Martha', 'Moxley', '(', 'Maggie', 'Grace', ')', 'moves', 'to', 'the', 'high', '-', 'class', 'area', 'of', 'Belle', 'Haven', ',', 'Greenwich', ',', 'Connecticut', '.', 'On', 'the', 'Mischief', 'Night', ',', 'eve', 'of', 'Halloween', ',', 'she', 'was', 'murdered', 'in', 'the', 'backyard', 'of', 'her', 'house', 'and', 'her', 'murder', 'remained', 'unsolved', '.', 'Twenty', '-', 'two', 'years', 'later', ',', 'the', 'writer', 'Mark', 'Fuhrman', '(', 'Christopher', 'Meloni', ')', ',', 'who', 'is', 'a', 'former', 'LA', 'detective', 'that', 'has', 'fallen', 'in', 'disgrace', 'for', 'perjury', 'in', 'O.J.', 'Simpson', 'trial', 'and', 'moved', 'to', 'Idaho', ',', 'decides', 'to', 'investigate', 'the', 'case', 'with', 'his', 'partner', 'Stephen', 'Weeks', '(', 'Andrew', 'Mitchell', ')', 'with', 'the', 'purpose', 'of', 'writing', 'a', 'book', '.', 'The', 'locals', 'squirm', 'and', 'do', 'not', 'welcome', 'them', ',', 'but', 'with', 'the', 'support', 'of', 'the', 'retired', 'detective', 'Steve', 'Carroll', '(', 'Robert', 'Forster', ')', 'that', 'was', 'in', 'charge', 'of', 'the', 'investigation', 'in', 'the', '70', \"'s\", ',', 'they', 'discover', 'the', 'criminal', 'and', 'a', 'net', 'of', 'power', 'and', 'money', 'to', 'cover', 'the', 'murder.<br', '/><br', '/>\"Murder', 'in', 'Greenwich', '\"', 'is', 'a', 'good', 'TV', 'movie', ',', 'with', 'the', 'true', 'story', 'of', 'a', 'murder', 'of', 'a', 'fifteen', 'years', 'old', 'girl', 'that', 'was', 'committed', 'by', 'a', 'wealthy', 'teenager', 'whose', 'mother', 'was', 'a', 'Kennedy', '.', 'The', 'powerful', 'and', 'rich', 'family', 'used', 'their', 'influence', 'to', 'cover', 'the', 'murder', 'for', 'more', 'than', 'twenty', 'years', '.', 'However', ',', 'a', 'snoopy', 'detective', 'and', 'convicted', 'perjurer', 'in', 'disgrace', 'was', 'able', 'to', 'disclose', 'how', 'the', 'hideous', 'crime', 'was', 'committed', '.', 'The', 'screenplay', 'shows', 'the', 'investigation', 'of', 'Mark', 'and', 'the', 'last', 'days', 'of', 'Martha', 'in', 'parallel', ',', 'but', 'there', 'is', 'a', 'lack', 'of', 'the', 'emotion', 'in', 'the', 'dramatization', '.', 'My', 'vote', 'is', 'seven.<br', '/><br', '/>Title', '(', 'Brazil', '):', 'Not', 'Available'], 'label_column': '1'}\n"
     ]
    }
   ],
   "source": [
    "text = torchtext.data.Field(\n",
    "    tokenize = 'spacy',\n",
    "    tokenizer_language='en_core_web_sm',\n",
    ")\n",
    "\n",
    "label = torchtext.data.LabelField(dtype=torch.long)\n",
    "\n",
    "fields = [('text_column', text), ('label_column', label)]\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path='../data/movie_data_cleaned.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=fields,\n",
    ")\n",
    "\n",
    "print(vars(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 35000\n",
      "Test data size: 10000\n",
      "Validation data size: 5000\n",
      "{'text_column': ['Pros', ':', 'Nothing', '<', 'br', '/><br', '/>Cons', ':', 'Everything', '<', 'br', '/><br', '/>Plot', 'summary', ':', 'A', 'female', 'reporter', 'runs', 'into', 'a', 'hitchhiker', 'that', 'tells', 'her', 'stories', 'about', 'the', 'deaths', 'of', 'people', 'that', 'were', 'killed', 'by', 'zombies.<br', '/><br', '/>Review', ':', 'Never', 'in', 'my', 'life', 'have', 'I', 'come', 'across', 'a', 'movie', 'as', 'bad', 'The', 'Zombie', 'Chronicles', '.', 'Filmed', 'on', 'a', 'budget', 'of', 'what', 'looks', 'to', 'be', 'about', '20', 'bucks', ',', 'TZC', 'is', 'a', 'completely', 'horrible', 'horror', 'movie', 'that', 'relies', 'on', 'lame', ',', 'forgetable', 'actors', 'whom', 'could', \"n't\", 'act', 'to', 'save', 'their', 'lives', 'and', 'gore', 'that', \"'s\", 'more', 'gross', 'than', 'frightening', '.', 'How', 'does', 'a', 'movie', 'like', 'this', 'even', 'get', 'made', '?', 'Simply', 'put', ',', 'avoid', 'TZC', 'like', 'a', 'sexually', '-', 'transmitted', 'disease.<br', '/><br', '/>My', 'last', '2', 'cents', ':', 'Humorously', 'enough', ',', 'this', 'movie', 'was', 'made', 'by', 'a', 'movie', 'company', 'called', 'Brain', 'Damage', 'Films', '.', 'They', \"'re\", 'brains', 'must', 'have', 'really', 'been', 'damaged', 'to', 'come', 'up', 'with', 'a', 'craptacular', 'movie', 'like', 'this.<br', '/><br', '/>My', 'rating', ':', '1', 'out', 'of', '10(If', 'it', 'were', 'up', 'to', 'me', ',', 'this', 'movie', 'would', 'get', 'the', 'rating', 'of', 'negative', 'bajillion', ')'], 'label_column': '0'}\n"
     ]
    }
   ],
   "source": [
    "# train_data, test_data, val_data = random_split(\n",
    "#     dataset,\n",
    "#     [int(len(dataset) * 0.7), int(len(dataset) * 0.2), int(len(dataset) * 0.1)],\n",
    "#     torch.Generator().manual_seed(random_seed),\n",
    "# )\n",
    "\n",
    "train_data, val_data, test_data = dataset.split(\n",
    "    split_ratio=[0.7, 0.2, 0.1],\n",
    "    random_state = random.seed(random_seed),\n",
    ")\n",
    "\n",
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Test data size: {len(test_data)}')\n",
    "print(f'Validation data size: {len(val_data)}')\n",
    "\n",
    "# Mengecek contoh train_data\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membangun Vocabulary / Kamus Kata\n",
    "- Vocabulary dibatasi sebesar 20000 (hanya menampilkan 20000 kata yang paling sering dipakai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "Label size: 2\n"
     ]
    }
   ],
   "source": [
    "text.build_vocab(train_data, max_size=vocabulary_size)\n",
    "label.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(text.vocab)}')\n",
    "print(f'Label size: {len(label.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 402761), (',', 381621), ('.', 328787), ('and', 217039), ('a', 216689), ('of', 200379), ('to', 185267), ('is', 150020), ('in', 122410), ('I', 108843), ('it', 106563), ('that', 96538), ('\"', 89116), (\"'s\", 85279), ('this', 84271), ('-', 73508), ('/><br', 70760), ('was', 69368), ('as', 59751), ('movie', 59142)]\n",
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
      "5\n",
      "defaultdict(None, {'1': 0, '0': 1})\n"
     ]
    }
   ],
   "source": [
    "# kata yang paling banyak muncul\n",
    "print(text.vocab.freqs.most_common(20))\n",
    "\n",
    "# 10 entri pertama (integer to string)\n",
    "print(text.vocab.itos[:10])\n",
    "\n",
    "# stoi : string to integer\n",
    "print(text.vocab.stoi['and'])\n",
    "\n",
    "# Label '1' atau positif ada di index 0, sementara label '0' atau negatif ada di indeks 1\n",
    "print(label.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 946x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 1068x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 60x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text_column]:[torch.LongTensor of size 52x128]\n",
      "\t[.label_column]:[torch.LongTensor of size 128]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=False,\n",
    "    sort_key=lambda x: len(x.text_column),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "check_iter = iter(train_loader)\n",
    "print(next(check_iter))\n",
    "print(next(check_iter))\n",
    "\n",
    "check_iter = iter(val_loader)\n",
    "print(next(check_iter))\n",
    "\n",
    "check_iter = iter(test_loader)\n",
    "print(next(check_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        # self.rnn = nn.RNN(embedding_dim, hidden_dim, nonlinearity='relu')\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        output = self.embedding(text)\n",
    "        output, (hidden, cell) = self.rnn(output)\n",
    "        hidden.squeeze_()\n",
    "        final_output = self.fc(hidden)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_size=len(text.vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_size=num_classes\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data.text_column.to(device)\n",
    "        labels = batch_data.label_column.to(device)\n",
    "        \n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch: {epoch} | Batch: {batch_idx}/{len(train_loader)} | Loss: {loss:.4f}')\n",
    "            \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        prediksi_benar = 0\n",
    "        jumlah_example = 0\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            \n",
    "            text = batch_data.text_column.to(device)\n",
    "            labels = batch_data.label_column.to(device)\n",
    "            \n",
    "            logits = model(text)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            \n",
    "            jumlah_example += len(preds)\n",
    "            prediksi_benar += (preds == labels).sum().item()\n",
    "            \n",
    "        print(f'Epoch: {epoch} | Accuracy: {prediksi_benar / jumlah_example}')\n",
    "\n",
    "print(f'Train time: {time.time() - train_start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# load model dari '../assets/model.pth' (Karena laptop saya tidak kuat nge-train model)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../assets/model.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      4\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:607\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    605\u001B[0m             opened_file\u001B[38;5;241m.\u001B[39mseek(orig_position)\n\u001B[1;32m    606\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mload(opened_file)\n\u001B[0;32m--> 607\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:882\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[1;32m    880\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m    881\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m--> 882\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    884\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m    886\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:857\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m    855\u001B[0m data_type, key, location, size \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m loaded_storages:\n\u001B[0;32m--> 857\u001B[0m     \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    858\u001B[0m storage \u001B[38;5;241m=\u001B[39m loaded_storages[key]\n\u001B[1;32m    859\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m storage\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:846\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(data_type, size, key, location)\u001B[0m\n\u001B[1;32m    843\u001B[0m dtype \u001B[38;5;241m=\u001B[39m data_type(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m    845\u001B[0m storage \u001B[38;5;241m=\u001B[39m zip_file\u001B[38;5;241m.\u001B[39mget_storage_from_record(name, size, dtype)\u001B[38;5;241m.\u001B[39mstorage()\n\u001B[0;32m--> 846\u001B[0m loaded_storages[key] \u001B[38;5;241m=\u001B[39m \u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:175\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 175\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    176\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:151\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 151\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_cuda_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    152\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    153\u001B[0m             storage_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda, \u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py:135\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[0;34m(location)\u001B[0m\n\u001B[1;32m    132\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_get_device_index(location, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    136\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    137\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    138\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    139\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    140\u001B[0m device_count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# load model dari '../assets/model.pth' (Karena laptop saya tidak kuat nge-train model)\n",
    "model.load_state_dict(torch.load('../assets/model.pth'))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    prediksi_benar = 0\n",
    "    jumlah_example = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(test_loader):\n",
    "\n",
    "        text = batch_data.text_column.to(device)\n",
    "        labels = batch_data.label_column.to(device)\n",
    "\n",
    "        logits = model(text)\n",
    "        _, preds = torch.max(logits, 1)\n",
    "\n",
    "        jumlah_example += len(preds)\n",
    "        prediksi_benar += (preds == labels).sum().item()\n",
    "\n",
    "    print(f'Test accuracy: {prediksi_benar / jumlah_example}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81b9ccaf5ef21c8a6faa6d42f6e42fcf9eafd7625a2befdd601079168fccee32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}