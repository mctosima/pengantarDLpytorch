{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "vocabulary_size = 20000\n",
    "lr = 0.005\n",
    "batch_size = 128\n",
    "num_epochs = 15\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset\n",
    "[Dataset Link](https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataaset csv disimpan dalam folder `data` dengan lokasi relatif satu level diatas notebook ini\n",
    "dataset_path = '../data/movie_data.csv' \n",
    "df = pd.read_csv(dataset_path)\n",
    "df.columns = ['text_column', 'label_column']\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/movie_data_cleaned.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mempersiapkan Data\n",
    "\n",
    "**Prasyarat:**\n",
    "- Paket `spacy` harus sudah terinstall di python anda\n",
    "- Anda juga perlu mengunduh vocabulary bahasa inggris dari spacy dengan cara mengetikkan perintah di bawah ini pada terminal anda\n",
    "\n",
    "```bash\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "**Penjelasan:**\n",
    "- Versi `torchtext` yang digunakan dalam tutorial ini adalah `0.6.0`. Jika anda ingin menggunakan `torchtext` versi terbaru, silahkan merujuk pada [standar API baru torchtext](https://colab.research.google.com/github/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb#scrollTo=jXUgsnxw70-M)\n",
    "- Tokenize akan mengubah kalimat pada teks menjadi token. Misalnya : `'Hello world'` menjadi `['Hello', 'world']`\n",
    "- Detail tentang `torchtext.data` dapat dilihat pada [tautan berikut](https://torchtext.readthedocs.io/en/latest/data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torchtext.data.Field(\n",
    "    tokenize = 'spacy',\n",
    "    tokenizer_language='en_core_web_sm',\n",
    ")\n",
    "\n",
    "label = torchtext.data.LabelField(dtype=torch.long)\n",
    "\n",
    "fields = [('text_column', text), ('label_column', label)]\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path='../data/movie_data_cleaned.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=fields,\n",
    ")\n",
    "\n",
    "print(vars(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data, val_data = random_split(\n",
    "#     dataset,\n",
    "#     [int(len(dataset) * 0.7), int(len(dataset) * 0.2), int(len(dataset) * 0.1)],\n",
    "#     torch.Generator().manual_seed(random_seed),\n",
    "# )\n",
    "\n",
    "train_data, val_data, test_data = dataset.split(\n",
    "    split_ratio=[0.7, 0.2, 0.1],\n",
    "    random_state = random.seed(random_seed),\n",
    ")\n",
    "\n",
    "print(f'Train data size: {len(train_data)}')\n",
    "print(f'Test data size: {len(test_data)}')\n",
    "print(f'Validation data size: {len(val_data)}')\n",
    "\n",
    "# Mengecek contoh train_data\n",
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membangun Vocabulary / Kamus Kata\n",
    "- Vocabulary dibatasi sebesar 20000 (hanya menampilkan 20000 kata yang paling sering dipakai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(train_data, max_size=vocabulary_size)\n",
    "label.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(text.vocab)}')\n",
    "print(f'Label size: {len(label.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kata yang paling banyak muncul\n",
    "print(text.vocab.freqs.most_common(20))\n",
    "\n",
    "# 10 entri pertama (integer to string)\n",
    "print(text.vocab.itos[:10])\n",
    "\n",
    "# stoi : string to integer\n",
    "print(text.vocab.stoi['and'])\n",
    "\n",
    "# Label '1' atau positif ada di index 0, sementara label '0' atau negatif ada di indeks 1\n",
    "print(label.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=False,\n",
    "    sort_key=lambda x: len(x.text_column),\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "check_iter = iter(train_loader)\n",
    "print(next(check_iter))\n",
    "print(next(check_iter))\n",
    "\n",
    "check_iter = iter(val_loader)\n",
    "print(next(check_iter))\n",
    "\n",
    "check_iter = iter(test_loader)\n",
    "print(next(check_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        # self.rnn = nn.RNN(embedding_dim, hidden_dim, nonlinearity='relu')\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        output = self.embedding(text)\n",
    "        output, (hidden, cell) = self.rnn(output)\n",
    "        hidden.squeeze_()\n",
    "        final_output = self.fc(hidden)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_size=len(text.vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_size=num_classes\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text = batch_data.text_column.to(device)\n",
    "        labels = batch_data.label_column.to(device)\n",
    "        \n",
    "        logits = model(text)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch: {epoch} | Batch: {batch_idx}/{len(train_loader)} | Loss: {loss:.4f}')\n",
    "            \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        prediksi_benar = 0\n",
    "        jumlah_example = 0\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            \n",
    "            text = batch_data.text_column.to(device)\n",
    "            labels = batch_data.label_column.to(device)\n",
    "            \n",
    "            logits = model(text)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            \n",
    "            jumlah_example += len(preds)\n",
    "            prediksi_benar += (preds == labels).sum().item()\n",
    "            \n",
    "        print(f'Epoch: {epoch} | Accuracy: {prediksi_benar / jumlah_example}')\n",
    "\n",
    "print(f'Train time: {time.time() - train_start_time}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81b9ccaf5ef21c8a6faa6d42f6e42fcf9eafd7625a2befdd601079168fccee32"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}